{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:46:44.960120: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-26 12:46:44.960165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-26 12:46:44.960960: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-26 12:46:44.966194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 12:46:45.607616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.datasets import load_train_test\n",
    "from src.portfolio import Portfolio\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  6 of 6 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Creating Training Set\n",
      "(2890, 126)\n",
      "(2890, 7)\n",
      "(2890, 7)\n",
      "========= Original Dataset =========\n",
      "features (2890, 126) columns 2012-07-06 00:00:00 2023-12-29 00:00:00\n",
      "targets (2890, 7) columns 2012-07-06 00:00:00 2023-12-29 00:00:00\n",
      "X (578, 10, 126)\n",
      "y (578, 7)\n",
      "y_price (578, 7)\n",
      "========= Train / Test Dataset =========\n",
      "X_train (462, 10, 126)\n",
      "X_test (116, 10, 126)\n",
      "y_train (462, 7)\n",
      "y_test (116, 7)\n",
      "y_price (578, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:46:47.739271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:47.759057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:47.759673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:47.761972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:47.762557: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:47.763116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:48.973483: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:48.974187: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:48.974201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-26 12:46:48.974820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-26 12:46:48.974842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3909 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/opt/ha/capstone/env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-02-26 12:46:49.466155: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:46:52.280163: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.1852 - loss: 0.3069 - val_accuracy: 0.0753 - val_loss: 0.1562\n",
      "Epoch 2/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1292 - loss: 0.1499 - val_accuracy: 0.1183 - val_loss: 0.1373\n",
      "Epoch 3/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1470 - loss: 0.1218 - val_accuracy: 0.1935 - val_loss: 0.1227\n",
      "Epoch 4/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1659 - loss: 0.1203 - val_accuracy: 0.1935 - val_loss: 0.1173\n",
      "Epoch 5/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1624 - loss: 0.1011 - val_accuracy: 0.1935 - val_loss: 0.1100\n",
      "Epoch 6/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1933 - loss: 0.0932 - val_accuracy: 0.2043 - val_loss: 0.1057\n",
      "Epoch 7/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1999 - loss: 0.0891 - val_accuracy: 0.2043 - val_loss: 0.1026\n",
      "Epoch 8/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2352 - loss: 0.0843 - val_accuracy: 0.2258 - val_loss: 0.0986\n",
      "Epoch 9/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2275 - loss: 0.0792 - val_accuracy: 0.2151 - val_loss: 0.0974\n",
      "Epoch 10/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2418 - loss: 0.0817 - val_accuracy: 0.1828 - val_loss: 0.0967\n",
      "Epoch 11/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2779 - loss: 0.0751 - val_accuracy: 0.2581 - val_loss: 0.0924\n",
      "Epoch 12/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2874 - loss: 0.0692 - val_accuracy: 0.1935 - val_loss: 0.0933\n",
      "Epoch 13/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2822 - loss: 0.0667 - val_accuracy: 0.2796 - val_loss: 0.0890\n",
      "Epoch 14/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3218 - loss: 0.0684 - val_accuracy: 0.1720 - val_loss: 0.0921\n",
      "Epoch 15/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3249 - loss: 0.0649 - val_accuracy: 0.3011 - val_loss: 0.0870\n",
      "Epoch 16/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3583 - loss: 0.0635 - val_accuracy: 0.2151 - val_loss: 0.0875\n",
      "Epoch 17/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3656 - loss: 0.0582 - val_accuracy: 0.2258 - val_loss: 0.0857\n",
      "Epoch 18/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3634 - loss: 0.0580 - val_accuracy: 0.2903 - val_loss: 0.0855\n",
      "Epoch 19/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3735 - loss: 0.0588 - val_accuracy: 0.1828 - val_loss: 0.0878\n",
      "Epoch 20/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3629 - loss: 0.0592 - val_accuracy: 0.2581 - val_loss: 0.0831\n",
      "Epoch 21/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3723 - loss: 0.0529 - val_accuracy: 0.2581 - val_loss: 0.0828\n",
      "Epoch 22/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3798 - loss: 0.0547 - val_accuracy: 0.2473 - val_loss: 0.0822\n",
      "Epoch 23/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4574 - loss: 0.0503 - val_accuracy: 0.2581 - val_loss: 0.0823\n",
      "Epoch 24/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4182 - loss: 0.0517 - val_accuracy: 0.2366 - val_loss: 0.0823\n",
      "Epoch 25/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4275 - loss: 0.0509 - val_accuracy: 0.2581 - val_loss: 0.0805\n",
      "Epoch 26/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4251 - loss: 0.0505 - val_accuracy: 0.2473 - val_loss: 0.0825\n",
      "Epoch 27/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4598 - loss: 0.0472 - val_accuracy: 0.2366 - val_loss: 0.0817\n",
      "Epoch 28/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4479 - loss: 0.0487 - val_accuracy: 0.2473 - val_loss: 0.0804\n",
      "Epoch 29/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4808 - loss: 0.0475 - val_accuracy: 0.2796 - val_loss: 0.0803\n",
      "Epoch 30/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5015 - loss: 0.0481 - val_accuracy: 0.2473 - val_loss: 0.0803\n",
      "Epoch 31/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4734 - loss: 0.0433 - val_accuracy: 0.2043 - val_loss: 0.0808\n",
      "Epoch 32/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5032 - loss: 0.0434 - val_accuracy: 0.2581 - val_loss: 0.0810\n",
      "Epoch 33/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4853 - loss: 0.0450 - val_accuracy: 0.2366 - val_loss: 0.0793\n",
      "Epoch 34/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5276 - loss: 0.0432 - val_accuracy: 0.2581 - val_loss: 0.0784\n",
      "Epoch 35/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5147 - loss: 0.0415 - val_accuracy: 0.2366 - val_loss: 0.0787\n",
      "Epoch 36/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5013 - loss: 0.0431 - val_accuracy: 0.2366 - val_loss: 0.0789\n",
      "Epoch 37/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5248 - loss: 0.0411 - val_accuracy: 0.2688 - val_loss: 0.0795\n",
      "Epoch 38/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5623 - loss: 0.0423 - val_accuracy: 0.2581 - val_loss: 0.0788\n",
      "Epoch 39/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5284 - loss: 0.0399 - val_accuracy: 0.2043 - val_loss: 0.0800\n",
      "Epoch 40/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5148 - loss: 0.0403 - val_accuracy: 0.2688 - val_loss: 0.0806\n",
      "Epoch 41/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5691 - loss: 0.0421 - val_accuracy: 0.2688 - val_loss: 0.0781\n",
      "Epoch 42/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6010 - loss: 0.0406 - val_accuracy: 0.1935 - val_loss: 0.0790\n",
      "Epoch 43/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5845 - loss: 0.0395 - val_accuracy: 0.2258 - val_loss: 0.0791\n",
      "Epoch 44/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5747 - loss: 0.0400 - val_accuracy: 0.2151 - val_loss: 0.0787\n",
      "Epoch 45/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6187 - loss: 0.0390 - val_accuracy: 0.2688 - val_loss: 0.0784\n",
      "Epoch 46/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5410 - loss: 0.0372 - val_accuracy: 0.2473 - val_loss: 0.0791\n",
      "Epoch 47/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5815 - loss: 0.0351 - val_accuracy: 0.2796 - val_loss: 0.0777\n",
      "Epoch 48/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5921 - loss: 0.0354 - val_accuracy: 0.2258 - val_loss: 0.0783\n",
      "Epoch 49/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6066 - loss: 0.0389 - val_accuracy: 0.2366 - val_loss: 0.0791\n",
      "Epoch 50/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5959 - loss: 0.0364 - val_accuracy: 0.2366 - val_loss: 0.0786\n",
      "Epoch 51/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5779 - loss: 0.0370 - val_accuracy: 0.2366 - val_loss: 0.0800\n",
      "Epoch 52/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5952 - loss: 0.0377 - val_accuracy: 0.2581 - val_loss: 0.0794\n",
      "Epoch 53/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6341 - loss: 0.0359 - val_accuracy: 0.2688 - val_loss: 0.0807\n",
      "Epoch 54/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6424 - loss: 0.0351 - val_accuracy: 0.2796 - val_loss: 0.0787\n",
      "Epoch 55/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6354 - loss: 0.0352 - val_accuracy: 0.2473 - val_loss: 0.0785\n",
      "Epoch 56/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6355 - loss: 0.0363 - val_accuracy: 0.2796 - val_loss: 0.0805\n",
      "Epoch 57/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6460 - loss: 0.0346 - val_accuracy: 0.2366 - val_loss: 0.0797\n",
      "Epoch 58/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5758 - loss: 0.0343 - val_accuracy: 0.2581 - val_loss: 0.0792\n",
      "Epoch 59/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 0.0324 - val_accuracy: 0.2688 - val_loss: 0.0787\n",
      "Epoch 60/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6010 - loss: 0.0341 - val_accuracy: 0.2581 - val_loss: 0.0796\n",
      "Epoch 61/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6516 - loss: 0.0347 - val_accuracy: 0.2043 - val_loss: 0.0810\n",
      "Epoch 62/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7013 - loss: 0.0321 - val_accuracy: 0.2258 - val_loss: 0.0802\n",
      "Epoch 63/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6475 - loss: 0.0341 - val_accuracy: 0.3011 - val_loss: 0.0798\n",
      "Epoch 64/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6194 - loss: 0.0333 - val_accuracy: 0.2581 - val_loss: 0.0803\n",
      "Epoch 65/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6653 - loss: 0.0328 - val_accuracy: 0.2151 - val_loss: 0.0794\n",
      "Epoch 66/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6506 - loss: 0.0338 - val_accuracy: 0.2473 - val_loss: 0.0816\n",
      "Epoch 67/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6480 - loss: 0.0315 - val_accuracy: 0.2796 - val_loss: 0.0787\n",
      "Epoch 68/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6667 - loss: 0.0310 - val_accuracy: 0.2366 - val_loss: 0.0802\n",
      "Epoch 69/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6648 - loss: 0.0328 - val_accuracy: 0.2581 - val_loss: 0.0805\n",
      "Epoch 70/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7071 - loss: 0.0308 - val_accuracy: 0.2473 - val_loss: 0.0797\n",
      "Epoch 71/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7069 - loss: 0.0310 - val_accuracy: 0.2151 - val_loss: 0.0807\n",
      "Epoch 72/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6846 - loss: 0.0296 - val_accuracy: 0.2581 - val_loss: 0.0804\n",
      "Epoch 73/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6803 - loss: 0.0310 - val_accuracy: 0.2903 - val_loss: 0.0800\n",
      "Epoch 74/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6940 - loss: 0.0314 - val_accuracy: 0.2043 - val_loss: 0.0813\n",
      "Epoch 75/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7048 - loss: 0.0308 - val_accuracy: 0.2581 - val_loss: 0.0812\n",
      "Epoch 76/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6684 - loss: 0.0308 - val_accuracy: 0.2688 - val_loss: 0.0804\n",
      "Epoch 77/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6930 - loss: 0.0311 - val_accuracy: 0.2043 - val_loss: 0.0819\n",
      "Epoch 78/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7126 - loss: 0.0302 - val_accuracy: 0.2581 - val_loss: 0.0821\n",
      "Epoch 79/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6560 - loss: 0.0290 - val_accuracy: 0.2473 - val_loss: 0.0815\n",
      "Epoch 80/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7031 - loss: 0.0298 - val_accuracy: 0.2473 - val_loss: 0.0820\n",
      "Epoch 81/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6451 - loss: 0.0302 - val_accuracy: 0.2688 - val_loss: 0.0825\n",
      "Epoch 82/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6827 - loss: 0.0287 - val_accuracy: 0.2581 - val_loss: 0.0813\n",
      "Epoch 83/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7218 - loss: 0.0314 - val_accuracy: 0.2366 - val_loss: 0.0823\n",
      "Epoch 84/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7172 - loss: 0.0285 - val_accuracy: 0.2473 - val_loss: 0.0831\n",
      "Epoch 85/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6707 - loss: 0.0289 - val_accuracy: 0.2151 - val_loss: 0.0815\n",
      "Epoch 86/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6518 - loss: 0.0275 - val_accuracy: 0.2473 - val_loss: 0.0819\n",
      "Epoch 87/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6915 - loss: 0.0287 - val_accuracy: 0.2258 - val_loss: 0.0835\n",
      "Epoch 88/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7013 - loss: 0.0276 - val_accuracy: 0.2258 - val_loss: 0.0829\n",
      "Epoch 89/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7169 - loss: 0.0284 - val_accuracy: 0.2258 - val_loss: 0.0824\n",
      "Epoch 90/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7244 - loss: 0.0272 - val_accuracy: 0.2473 - val_loss: 0.0838\n",
      "Epoch 91/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6872 - loss: 0.0273 - val_accuracy: 0.2581 - val_loss: 0.0836\n",
      "Epoch 92/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6871 - loss: 0.0285 - val_accuracy: 0.2151 - val_loss: 0.0843\n",
      "Epoch 93/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7047 - loss: 0.0282 - val_accuracy: 0.2258 - val_loss: 0.0844\n",
      "Epoch 94/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6288 - loss: 0.0271 - val_accuracy: 0.2688 - val_loss: 0.0845\n",
      "Epoch 95/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6909 - loss: 0.0296 - val_accuracy: 0.2258 - val_loss: 0.0836\n",
      "Epoch 96/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6789 - loss: 0.0271 - val_accuracy: 0.2258 - val_loss: 0.0847\n",
      "Epoch 97/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6795 - loss: 0.0294 - val_accuracy: 0.2258 - val_loss: 0.0848\n",
      "Epoch 98/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6960 - loss: 0.0257 - val_accuracy: 0.2581 - val_loss: 0.0844\n",
      "Epoch 99/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7222 - loss: 0.0268 - val_accuracy: 0.2581 - val_loss: 0.0837\n",
      "Epoch 100/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7285 - loss: 0.0272 - val_accuracy: 0.2366 - val_loss: 0.0851\n",
      "Epoch 101/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7105 - loss: 0.0258 - val_accuracy: 0.2258 - val_loss: 0.0854\n",
      "Epoch 102/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6620 - loss: 0.0253 - val_accuracy: 0.1935 - val_loss: 0.0855\n",
      "Epoch 103/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6893 - loss: 0.0251 - val_accuracy: 0.2581 - val_loss: 0.0851\n",
      "Epoch 104/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7512 - loss: 0.0255 - val_accuracy: 0.2366 - val_loss: 0.0857\n",
      "Epoch 105/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7429 - loss: 0.0261 - val_accuracy: 0.2151 - val_loss: 0.0873\n",
      "Epoch 106/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6957 - loss: 0.0259 - val_accuracy: 0.2258 - val_loss: 0.0863\n",
      "Epoch 107/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7196 - loss: 0.0255 - val_accuracy: 0.2258 - val_loss: 0.0858\n",
      "Epoch 108/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7626 - loss: 0.0255 - val_accuracy: 0.2581 - val_loss: 0.0865\n",
      "Epoch 109/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7152 - loss: 0.0266 - val_accuracy: 0.2473 - val_loss: 0.0868\n",
      "Epoch 110/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7106 - loss: 0.0268 - val_accuracy: 0.1935 - val_loss: 0.0889\n",
      "Epoch 111/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6970 - loss: 0.0256 - val_accuracy: 0.2366 - val_loss: 0.0865\n",
      "Epoch 112/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7005 - loss: 0.0253 - val_accuracy: 0.2366 - val_loss: 0.0878\n",
      "Epoch 113/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7326 - loss: 0.0264 - val_accuracy: 0.2366 - val_loss: 0.0874\n",
      "Epoch 114/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7441 - loss: 0.0231 - val_accuracy: 0.2581 - val_loss: 0.0876\n",
      "Epoch 115/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.0245 - val_accuracy: 0.2473 - val_loss: 0.0876\n",
      "Epoch 116/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7364 - loss: 0.0262 - val_accuracy: 0.2043 - val_loss: 0.0892\n",
      "Epoch 117/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7682 - loss: 0.0256 - val_accuracy: 0.1935 - val_loss: 0.0889\n",
      "Epoch 118/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7260 - loss: 0.0248 - val_accuracy: 0.2473 - val_loss: 0.0876\n",
      "Epoch 119/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7317 - loss: 0.0250 - val_accuracy: 0.2366 - val_loss: 0.0889\n",
      "Epoch 120/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7520 - loss: 0.0245 - val_accuracy: 0.2258 - val_loss: 0.0885\n",
      "Epoch 121/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7178 - loss: 0.0239 - val_accuracy: 0.2151 - val_loss: 0.0886\n",
      "Epoch 122/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7264 - loss: 0.0244 - val_accuracy: 0.2581 - val_loss: 0.0889\n",
      "Epoch 123/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7370 - loss: 0.0249 - val_accuracy: 0.2366 - val_loss: 0.0891\n",
      "Epoch 124/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7401 - loss: 0.0238 - val_accuracy: 0.2043 - val_loss: 0.0897\n",
      "Epoch 125/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7422 - loss: 0.0230 - val_accuracy: 0.2151 - val_loss: 0.0911\n",
      "Epoch 126/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7071 - loss: 0.0251 - val_accuracy: 0.2151 - val_loss: 0.0912\n",
      "Epoch 127/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7326 - loss: 0.0229 - val_accuracy: 0.2473 - val_loss: 0.0903\n",
      "Epoch 128/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7111 - loss: 0.0246 - val_accuracy: 0.2366 - val_loss: 0.0906\n",
      "Epoch 129/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7295 - loss: 0.0249 - val_accuracy: 0.2258 - val_loss: 0.0908\n",
      "Epoch 130/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7388 - loss: 0.0220 - val_accuracy: 0.2473 - val_loss: 0.0913\n",
      "Epoch 131/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7622 - loss: 0.0232 - val_accuracy: 0.2258 - val_loss: 0.0909\n",
      "Epoch 132/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7158 - loss: 0.0230 - val_accuracy: 0.2366 - val_loss: 0.0913\n",
      "Epoch 133/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7109 - loss: 0.0239 - val_accuracy: 0.2151 - val_loss: 0.0911\n",
      "Epoch 134/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7612 - loss: 0.0224 - val_accuracy: 0.2258 - val_loss: 0.0920\n",
      "Epoch 135/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7228 - loss: 0.0242 - val_accuracy: 0.2258 - val_loss: 0.0930\n",
      "Epoch 136/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7329 - loss: 0.0242 - val_accuracy: 0.2151 - val_loss: 0.0914\n",
      "Epoch 137/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7537 - loss: 0.0225 - val_accuracy: 0.2258 - val_loss: 0.0921\n",
      "Epoch 138/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7086 - loss: 0.0239 - val_accuracy: 0.2366 - val_loss: 0.0922\n",
      "Epoch 139/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7619 - loss: 0.0229 - val_accuracy: 0.2258 - val_loss: 0.0922\n",
      "Epoch 140/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7292 - loss: 0.0240 - val_accuracy: 0.2581 - val_loss: 0.0939\n",
      "Epoch 141/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7776 - loss: 0.0223 - val_accuracy: 0.2151 - val_loss: 0.0958\n",
      "Epoch 142/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7337 - loss: 0.0231 - val_accuracy: 0.2151 - val_loss: 0.0935\n",
      "Epoch 143/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7591 - loss: 0.0217 - val_accuracy: 0.2473 - val_loss: 0.0937\n",
      "Epoch 144/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7490 - loss: 0.0210 - val_accuracy: 0.2258 - val_loss: 0.0936\n",
      "Epoch 145/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7718 - loss: 0.0225 - val_accuracy: 0.1828 - val_loss: 0.0956\n",
      "Epoch 146/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7254 - loss: 0.0217 - val_accuracy: 0.2043 - val_loss: 0.0946\n",
      "Epoch 147/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7527 - loss: 0.0236 - val_accuracy: 0.2366 - val_loss: 0.0957\n",
      "Epoch 148/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7270 - loss: 0.0225 - val_accuracy: 0.2258 - val_loss: 0.0948\n",
      "Epoch 149/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7672 - loss: 0.0226 - val_accuracy: 0.2043 - val_loss: 0.0966\n",
      "Epoch 150/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7620 - loss: 0.0223 - val_accuracy: 0.2258 - val_loss: 0.0957\n",
      "Epoch 151/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7436 - loss: 0.0219 - val_accuracy: 0.2258 - val_loss: 0.0965\n",
      "Epoch 152/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7668 - loss: 0.0220 - val_accuracy: 0.2473 - val_loss: 0.0962\n",
      "Epoch 153/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7448 - loss: 0.0225 - val_accuracy: 0.2151 - val_loss: 0.0961\n",
      "Epoch 154/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7408 - loss: 0.0201 - val_accuracy: 0.2151 - val_loss: 0.0977\n",
      "Epoch 155/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7578 - loss: 0.0219 - val_accuracy: 0.2473 - val_loss: 0.0979\n",
      "Epoch 156/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7675 - loss: 0.0226 - val_accuracy: 0.2151 - val_loss: 0.0975\n",
      "Epoch 157/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7486 - loss: 0.0213 - val_accuracy: 0.2258 - val_loss: 0.0975\n",
      "Epoch 158/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7862 - loss: 0.0221 - val_accuracy: 0.2151 - val_loss: 0.0977\n",
      "Epoch 159/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7405 - loss: 0.0218 - val_accuracy: 0.2043 - val_loss: 0.0979\n",
      "Epoch 160/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7698 - loss: 0.0219 - val_accuracy: 0.2258 - val_loss: 0.0984\n",
      "Epoch 161/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7288 - loss: 0.0207 - val_accuracy: 0.2688 - val_loss: 0.0980\n",
      "Epoch 162/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7403 - loss: 0.0210 - val_accuracy: 0.2258 - val_loss: 0.0978\n",
      "Epoch 163/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7871 - loss: 0.0212 - val_accuracy: 0.2043 - val_loss: 0.1002\n",
      "Epoch 164/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7836 - loss: 0.0223 - val_accuracy: 0.2366 - val_loss: 0.1001\n",
      "Epoch 165/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7286 - loss: 0.0214 - val_accuracy: 0.2258 - val_loss: 0.0999\n",
      "Epoch 166/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7724 - loss: 0.0208 - val_accuracy: 0.2151 - val_loss: 0.1012\n",
      "Epoch 167/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7602 - loss: 0.0204 - val_accuracy: 0.2043 - val_loss: 0.1012\n",
      "Epoch 168/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7578 - loss: 0.0208 - val_accuracy: 0.2581 - val_loss: 0.1017\n",
      "Epoch 169/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7609 - loss: 0.0201 - val_accuracy: 0.1828 - val_loss: 0.1020\n",
      "Epoch 170/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7639 - loss: 0.0209 - val_accuracy: 0.2151 - val_loss: 0.1022\n",
      "Epoch 171/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7538 - loss: 0.0216 - val_accuracy: 0.2581 - val_loss: 0.1016\n",
      "Epoch 172/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7891 - loss: 0.0206 - val_accuracy: 0.2151 - val_loss: 0.1017\n",
      "Epoch 173/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7650 - loss: 0.0191 - val_accuracy: 0.1828 - val_loss: 0.1027\n",
      "Epoch 174/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.0225 - val_accuracy: 0.2473 - val_loss: 0.1038\n",
      "Epoch 175/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7731 - loss: 0.0209 - val_accuracy: 0.2258 - val_loss: 0.1016\n",
      "Epoch 176/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7839 - loss: 0.0208 - val_accuracy: 0.2258 - val_loss: 0.1026\n",
      "Epoch 177/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7742 - loss: 0.0192 - val_accuracy: 0.2258 - val_loss: 0.1017\n",
      "Epoch 178/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7446 - loss: 0.0222 - val_accuracy: 0.1935 - val_loss: 0.1041\n",
      "Epoch 179/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7518 - loss: 0.0207 - val_accuracy: 0.2258 - val_loss: 0.1044\n",
      "Epoch 180/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7260 - loss: 0.0212 - val_accuracy: 0.2688 - val_loss: 0.1037\n",
      "Epoch 181/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7859 - loss: 0.0199 - val_accuracy: 0.1935 - val_loss: 0.1044\n",
      "Epoch 182/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7483 - loss: 0.0200 - val_accuracy: 0.1935 - val_loss: 0.1049\n",
      "Epoch 183/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7636 - loss: 0.0199 - val_accuracy: 0.1828 - val_loss: 0.1054\n",
      "Epoch 184/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7846 - loss: 0.0209 - val_accuracy: 0.2581 - val_loss: 0.1044\n",
      "Epoch 185/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7599 - loss: 0.0193 - val_accuracy: 0.2473 - val_loss: 0.1054\n",
      "Epoch 186/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7941 - loss: 0.0202 - val_accuracy: 0.2151 - val_loss: 0.1052\n",
      "Epoch 187/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7349 - loss: 0.0196 - val_accuracy: 0.2366 - val_loss: 0.1055\n",
      "Epoch 188/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7590 - loss: 0.0200 - val_accuracy: 0.2151 - val_loss: 0.1062\n",
      "Epoch 189/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.0203 - val_accuracy: 0.2473 - val_loss: 0.1055\n",
      "Epoch 190/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8047 - loss: 0.0201 - val_accuracy: 0.2473 - val_loss: 0.1059\n",
      "Epoch 191/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7883 - loss: 0.0196 - val_accuracy: 0.2151 - val_loss: 0.1075\n",
      "Epoch 192/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7681 - loss: 0.0205 - val_accuracy: 0.2366 - val_loss: 0.1064\n",
      "Epoch 193/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7913 - loss: 0.0202 - val_accuracy: 0.2151 - val_loss: 0.1071\n",
      "Epoch 194/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7378 - loss: 0.0199 - val_accuracy: 0.2043 - val_loss: 0.1094\n",
      "Epoch 195/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7869 - loss: 0.0198 - val_accuracy: 0.2258 - val_loss: 0.1075\n",
      "Epoch 196/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7733 - loss: 0.0200 - val_accuracy: 0.2258 - val_loss: 0.1094\n",
      "Epoch 197/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7608 - loss: 0.0189 - val_accuracy: 0.2258 - val_loss: 0.1086\n",
      "Epoch 198/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7922 - loss: 0.0197 - val_accuracy: 0.2043 - val_loss: 0.1092\n",
      "Epoch 199/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8019 - loss: 0.0202 - val_accuracy: 0.2366 - val_loss: 0.1099\n",
      "Epoch 200/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7656 - loss: 0.0200 - val_accuracy: 0.2473 - val_loss: 0.1096\n",
      "Epoch 201/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7448 - loss: 0.0197 - val_accuracy: 0.2581 - val_loss: 0.1089\n",
      "Epoch 202/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7414 - loss: 0.0186 - val_accuracy: 0.2151 - val_loss: 0.1102\n",
      "Epoch 203/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7606 - loss: 0.0196 - val_accuracy: 0.1935 - val_loss: 0.1100\n",
      "Epoch 204/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7726 - loss: 0.0203 - val_accuracy: 0.2151 - val_loss: 0.1106\n",
      "Epoch 205/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7501 - loss: 0.0187 - val_accuracy: 0.2366 - val_loss: 0.1102\n",
      "Epoch 206/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7967 - loss: 0.0196 - val_accuracy: 0.2258 - val_loss: 0.1108\n",
      "Epoch 207/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7937 - loss: 0.0206 - val_accuracy: 0.2366 - val_loss: 0.1117\n",
      "Epoch 208/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7527 - loss: 0.0195 - val_accuracy: 0.2473 - val_loss: 0.1112\n",
      "Epoch 209/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7793 - loss: 0.0189 - val_accuracy: 0.2366 - val_loss: 0.1111\n",
      "Epoch 210/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8181 - loss: 0.0194 - val_accuracy: 0.2473 - val_loss: 0.1118\n",
      "Epoch 211/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7925 - loss: 0.0193 - val_accuracy: 0.1935 - val_loss: 0.1121\n",
      "Epoch 212/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7717 - loss: 0.0189 - val_accuracy: 0.2366 - val_loss: 0.1116\n",
      "Epoch 213/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7636 - loss: 0.0185 - val_accuracy: 0.2258 - val_loss: 0.1129\n",
      "Epoch 214/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7248 - loss: 0.0192 - val_accuracy: 0.2366 - val_loss: 0.1121\n",
      "Epoch 215/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7954 - loss: 0.0192 - val_accuracy: 0.2258 - val_loss: 0.1131\n",
      "Epoch 216/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8093 - loss: 0.0191 - val_accuracy: 0.2043 - val_loss: 0.1141\n",
      "Epoch 217/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8119 - loss: 0.0192 - val_accuracy: 0.2258 - val_loss: 0.1133\n",
      "Epoch 218/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7496 - loss: 0.0197 - val_accuracy: 0.2366 - val_loss: 0.1135\n",
      "Epoch 219/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7886 - loss: 0.0196 - val_accuracy: 0.2258 - val_loss: 0.1159\n",
      "Epoch 220/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7691 - loss: 0.0190 - val_accuracy: 0.2043 - val_loss: 0.1151\n",
      "Epoch 221/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7943 - loss: 0.0182 - val_accuracy: 0.2366 - val_loss: 0.1151\n",
      "Epoch 222/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8036 - loss: 0.0180 - val_accuracy: 0.2258 - val_loss: 0.1160\n",
      "Epoch 223/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7869 - loss: 0.0187 - val_accuracy: 0.2366 - val_loss: 0.1167\n",
      "Epoch 224/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7756 - loss: 0.0175 - val_accuracy: 0.2366 - val_loss: 0.1151\n",
      "Epoch 225/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7457 - loss: 0.0190 - val_accuracy: 0.2366 - val_loss: 0.1160\n",
      "Epoch 226/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8003 - loss: 0.0184 - val_accuracy: 0.2366 - val_loss: 0.1171\n",
      "Epoch 227/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7896 - loss: 0.0179 - val_accuracy: 0.2258 - val_loss: 0.1164\n",
      "Epoch 228/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7890 - loss: 0.0193 - val_accuracy: 0.2151 - val_loss: 0.1165\n",
      "Epoch 229/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7544 - loss: 0.0195 - val_accuracy: 0.2366 - val_loss: 0.1175\n",
      "Epoch 230/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7579 - loss: 0.0183 - val_accuracy: 0.2366 - val_loss: 0.1175\n",
      "Epoch 231/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7634 - loss: 0.0178 - val_accuracy: 0.2366 - val_loss: 0.1185\n",
      "Epoch 232/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7844 - loss: 0.0183 - val_accuracy: 0.2151 - val_loss: 0.1185\n",
      "Epoch 233/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7855 - loss: 0.0188 - val_accuracy: 0.2258 - val_loss: 0.1187\n",
      "Epoch 234/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7680 - loss: 0.0192 - val_accuracy: 0.2258 - val_loss: 0.1185\n",
      "Epoch 235/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7661 - loss: 0.0178 - val_accuracy: 0.2473 - val_loss: 0.1185\n",
      "Epoch 236/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7740 - loss: 0.0178 - val_accuracy: 0.2473 - val_loss: 0.1193\n",
      "Epoch 237/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7549 - loss: 0.0176 - val_accuracy: 0.2151 - val_loss: 0.1198\n",
      "Epoch 238/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7731 - loss: 0.0182 - val_accuracy: 0.2043 - val_loss: 0.1205\n",
      "Epoch 239/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7996 - loss: 0.0186 - val_accuracy: 0.2366 - val_loss: 0.1214\n",
      "Epoch 240/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7905 - loss: 0.0183 - val_accuracy: 0.2688 - val_loss: 0.1198\n",
      "Epoch 241/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7829 - loss: 0.0182 - val_accuracy: 0.2258 - val_loss: 0.1220\n",
      "Epoch 242/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7994 - loss: 0.0174 - val_accuracy: 0.2151 - val_loss: 0.1211\n",
      "Epoch 243/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7927 - loss: 0.0180 - val_accuracy: 0.2473 - val_loss: 0.1210\n",
      "Epoch 244/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7991 - loss: 0.0188 - val_accuracy: 0.2258 - val_loss: 0.1208\n",
      "Epoch 245/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7680 - loss: 0.0191 - val_accuracy: 0.2258 - val_loss: 0.1218\n",
      "Epoch 246/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8223 - loss: 0.0177 - val_accuracy: 0.2258 - val_loss: 0.1221\n",
      "Epoch 247/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8181 - loss: 0.0173 - val_accuracy: 0.2258 - val_loss: 0.1233\n",
      "Epoch 248/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7642 - loss: 0.0171 - val_accuracy: 0.2258 - val_loss: 0.1231\n",
      "Epoch 249/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7952 - loss: 0.0167 - val_accuracy: 0.2581 - val_loss: 0.1224\n",
      "Epoch 250/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7864 - loss: 0.0193 - val_accuracy: 0.2366 - val_loss: 0.1240\n",
      "Epoch 251/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7805 - loss: 0.0178 - val_accuracy: 0.2258 - val_loss: 0.1244\n",
      "Epoch 252/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8230 - loss: 0.0178 - val_accuracy: 0.2366 - val_loss: 0.1245\n",
      "Epoch 253/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8137 - loss: 0.0178 - val_accuracy: 0.2258 - val_loss: 0.1244\n",
      "Epoch 254/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7782 - loss: 0.0180 - val_accuracy: 0.2258 - val_loss: 0.1251\n",
      "Epoch 255/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7739 - loss: 0.0183 - val_accuracy: 0.2258 - val_loss: 0.1246\n",
      "Epoch 256/256\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7795 - loss: 0.0175 - val_accuracy: 0.2258 - val_loss: 0.1256\n",
      "      returns   cum_returns\n",
      "0    0.032660  1.032660e+00\n",
      "1    0.042385  1.076429e+00\n",
      "2    0.064106  1.145434e+00\n",
      "3    0.041022  1.192422e+00\n",
      "4    0.020326  1.216660e+00\n",
      "..        ...           ...\n",
      "573  0.004733  4.067769e+09\n",
      "574  0.034417  4.207769e+09\n",
      "575  0.028552  4.327908e+09\n",
      "576  0.054070  4.561917e+09\n",
      "577  0.000000  4.561917e+09\n",
      "\n",
      "[578 rows x 2 columns]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "----------- predicted -----------\n",
      "      returns  cum_returns\n",
      "0    0.018381     1.018381\n",
      "1   -0.052550     0.964866\n",
      "2    0.029580     0.993407\n",
      "3    0.007516     1.000873\n",
      "4    0.011714     1.012597\n",
      "..        ...          ...\n",
      "573  0.000000     3.192857\n",
      "574  0.000000     3.192857\n",
      "575  0.000000     3.192857\n",
      "576  0.000000     3.192857\n",
      "577  0.000000     3.192857\n",
      "\n",
      "[578 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(X_train, y_train, num_epochs, batch_size, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=X_train.shape[2]*4, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(units=y_train.shape[1]))  # output for optimal weights for next week.\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.2, verbose=1)\n",
    "    return model\n",
    "\n",
    "tickers = ['AAPL', 'MSFT', 'GOOG', 'META', 'TSLA', 'SPY']\n",
    "start = '2010-01-01'\n",
    "end = '2024-01-01'\n",
    "num_epochs=256\n",
    "batch_size=32\n",
    "learning_rate=0.001\n",
    "\n",
    "yfdata, features, targets, X, y, y_price = load_train_test(tickers, start, end)\n",
    "\n",
    "print('========= Original Dataset =========')\n",
    "print('features', features.shape, 'columns', features.index[0], features.index[-1])\n",
    "print('targets', targets.shape, 'columns', targets.index[0], targets.index[-1])\n",
    "print('X', X.shape)\n",
    "print('y', y.shape)\n",
    "print('y_price', y_price.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print('========= Train / Test Dataset =========')\n",
    "print('X_train', X_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_test', y_test.shape)\n",
    "print('y_price', y_price.shape)\n",
    "\n",
    "model = train(X_train, y_train, num_epochs, batch_size, learning_rate)\n",
    "\n",
    "optimal_test_portfolio = Portfolio.portfolio_returns(y, y_price)\n",
    "print(optimal_test_portfolio)\n",
    "predicted_test_portfolio = Portfolio.portfolio_returns(model.predict(X_test), y_price)\n",
    "\n",
    "print('----------- predicted -----------')\n",
    "print(predicted_test_portfolio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
